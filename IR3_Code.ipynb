{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7969043,"sourceType":"datasetVersion","datasetId":4688916},{"sourceId":7969348,"sourceType":"datasetVersion","datasetId":4689122}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-07T07:37:27.530130Z","iopub.execute_input":"2024-04-07T07:37:27.531740Z","iopub.status.idle":"2024-04-07T07:37:28.856250Z","shell.execute_reply.started":"2024-04-07T07:37:27.531686Z","shell.execute_reply":"2024-04-07T07:37:28.855156Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/ir-metadata/meta_Electronics.json\n/kaggle/input/ir-assignment3/Electronics_5.json\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport json\n\ndef parse(path):\n    with open(path, 'r') as file:\n        for line in file:\n            yield json.loads(line)\n\ndef getDF(path):\n    i = 0\n    df = {}\n    for d in parse(path):\n        df[i] = d\n        i += 1\n    return pd.DataFrame.from_dict(df, orient='index')\n\ndf = getDF('/kaggle/input/ir-assignment3/Electronics_5.json')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:37:31.906051Z","iopub.execute_input":"2024-04-07T07:37:31.907276Z","iopub.status.idle":"2024-04-07T07:41:05.968141Z","shell.execute_reply.started":"2024-04-07T07:37:31.907229Z","shell.execute_reply":"2024-04-07T07:41:05.966282Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(df.head(10))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:41:57.772470Z","iopub.execute_input":"2024-04-07T07:41:57.773132Z","iopub.status.idle":"2024-04-07T07:41:57.876562Z","shell.execute_reply.started":"2024-04-07T07:41:57.773086Z","shell.execute_reply":"2024-04-07T07:41:57.875540Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"   overall vote  verified   reviewTime      reviewerID        asin  \\\n0      5.0   67      True  09 18, 1999   AAP7PPBU72QFM  0151004714   \n1      3.0    5      True  10 23, 2013  A2E168DTVGE6SV  0151004714   \n2      5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3  0151004714   \n3      5.0   13     False   09 4, 2000  A1T17LMQABMBN5  0151004714   \n4      3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE  0151004714   \n5      4.0  NaN      True   06 5, 2013  A3IYSOTP3HA77N  0380709473   \n6      5.0  NaN      True  06 27, 2016  A11SXV34PZUQ5E  0380709473   \n7      5.0  NaN      True  07 30, 2015  A2AUQM1HT2D5T8  0380709473   \n8      5.0  NaN      True  02 16, 2015  A3UD8JRWLX6SRX  0380709473   \n9      4.0  NaN     False  11 21, 2013  A3MV1KKHX51FYT  0380709473   \n\n                            style      reviewerName  \\\n0       {'Format:': ' Hardcover'}      D. C. Carrad   \n1  {'Format:': ' Kindle Edition'}               Evy   \n2       {'Format:': ' Paperback'}             Kcorn   \n3       {'Format:': ' Hardcover'}   Caf Girl Writes   \n4       {'Format:': ' Hardcover'}  W. Shane Schmidt   \n5  {'Format:': ' Kindle Edition'}          B. Marks   \n6  {'Format:': ' Kindle Edition'}            Tom C.   \n7  {'Format:': ' Kindle Edition'}               ema   \n8       {'Format:': ' Paperback'}        Michael O.   \n9       {'Format:': ' Paperback'}    Acute Observer   \n\n                                          reviewText  \\\n0  This is the best novel I have read in 2 or 3 y...   \n1  Pages and pages of introspection, in the style...   \n2  This is the kind of novel to read when you hav...   \n3  What gorgeous language! What an incredible wri...   \n4  I was taken in by reviews that compared this b...   \n5  I read this probably 50 years ago in my youth ...   \n6  I read every Perry mason book voraciously. Fin...   \n7  I love this series of Bertha and Lamb..  Great...   \n8                                        Great read!   \n9  Crows Can't Count, A.A. Fair\\n\\nMr. Harry Shar...   \n\n                                             summary  unixReviewTime image  \n0                                     A star is born       937612800   NaN  \n1                    A stream of consciousness novel      1382486400   NaN  \n2  I'm a huge fan of the author and this one did ...      1220313600   NaN  \n3          The most beautiful book I have ever read!       968025600   NaN  \n4                        A dissenting view--In part.       949622400   NaN  \n5                              Above average mystery      1370390400   NaN  \n6                                       Lam is cool!      1466985600   NaN  \n7                                         Five Stars      1438214400   NaN  \n8                                         Five Stars      1424044800   NaN  \n9                    A Fast and Far Moving Adventure      1384992000   NaN  \n","output_type":"stream"}]},{"cell_type":"code","source":"chosen_product_title = \"Headphones\"\nchosen_product = df.loc[df['vote'] == chosen_product_title]\n\n# Displaying the chosen product\nprint(chosen_product)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:42:36.137288Z","iopub.execute_input":"2024-04-07T07:42:36.137772Z","iopub.status.idle":"2024-04-07T07:42:36.678573Z","shell.execute_reply.started":"2024-04-07T07:42:36.137737Z","shell.execute_reply":"2024-04-07T07:42:36.677058Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Empty DataFrame\nColumns: [overall, vote, verified, reviewTime, reviewerID, asin, style, reviewerName, reviewText, summary, unixReviewTime, image]\nIndex: []\n","output_type":"stream"}]},{"cell_type":"code","source":"num_rows = df.shape[0]\nprint(\"Number of rows in the DataFrame:\", num_rows)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:42:38.912066Z","iopub.execute_input":"2024-04-07T07:42:38.912706Z","iopub.status.idle":"2024-04-07T07:42:38.920617Z","shell.execute_reply.started":"2024-04-07T07:42:38.912654Z","shell.execute_reply":"2024-04-07T07:42:38.919204Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Number of rows in the DataFrame: 6739590\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Reading Metadata","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport json\n\ndef parse(path):\n    with open(path, 'r') as file:\n        for line in file:\n            yield json.loads(line)\n\ndef getDF(path):\n    i = 0\n    df = {}\n    for d in parse(path):\n        df[i] = d\n        i += 1\n    return pd.DataFrame.from_dict(df, orient='index')\n\ndf1 = getDF('/kaggle/input/ir-metadata/meta_Electronics.json')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:42:41.132187Z","iopub.execute_input":"2024-04-07T07:42:41.132708Z","iopub.status.idle":"2024-04-07T07:46:14.343870Z","shell.execute_reply.started":"2024-04-07T07:42:41.132667Z","shell.execute_reply":"2024-04-07T07:46:14.342405Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(df1.head(10))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:46:51.942668Z","iopub.execute_input":"2024-04-07T07:46:51.943748Z","iopub.status.idle":"2024-04-07T07:46:52.055694Z","shell.execute_reply.started":"2024-04-07T07:46:51.943698Z","shell.execute_reply":"2024-04-07T07:46:52.054778Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"                                            category tech1  \\\n0  [Electronics, Camera &amp; Photo, Video Survei...         \n1                  [Electronics, Camera &amp; Photo]         \n2  [Electronics, eBook Readers &amp; Accessories,...         \n3  [Electronics, eBook Readers & Accessories, eBo...         \n4  [Electronics, eBook Readers & Accessories, eBo...         \n5  [Electronics, eBook Readers &amp; Accessories,...         \n6  [Electronics, eBook Readers & Accessories, eBo...         \n7  [Electronics, Portable Audio & Video, MP3 & MP...         \n8       [Electronics, Headphones, Earbud Headphones]         \n9  [Electronics, Computers &amp; Accessories, Com...         \n\n                                         description fit  \\\n0  [The following camera brands and models have b...       \n1  [This second edition of the Handbook of Astron...       \n2  [A zesty tale. (Publishers Weekly)<br /><br />...       \n3                                                 []       \n4  [&#8220;sex.lies.murder.fame. is brillllli&#82...       \n5                                               [, ]       \n6  [GIRL WITH A ONE-TRACK MIND: CONFESSIONS OF TH...       \n7  [Support system: Windows XP/Vsita/7 * SNR: 85d...       \n8  [, <b>True High Definition Sound:</b><br>With ...       \n9                                                 []       \n\n                                               title  \\\n0  Genuine Geovision 1 Channel 3rd Party NVR IP S...   \n1  Books \"Handbook of Astronomical Image Processi...   \n2                                     One Hot Summer   \n3  Hurray for Hattie Rabbit: Story and pictures (...   \n4                     sex.lies.murder.fame.: A Novel   \n5                                    College Physics   \n6  Girl with a One-track Mind: Confessions of the...   \n7  abcGoodefg&reg; 4GB USB 2.0 Mp3 Music Player w...   \n8  Wireless Bluetooth Headphones Earbuds with Mic...   \n9  Kelby Training DVD: Mastering Blend Modes in A...   \n\n                                            also_buy tech2  \\\n0                                                 []         \n1                                       [0999470906]         \n2                           [0425167798, 039914157X]         \n3               [0060219521, 0060219580, 0060219394]         \n4                                                 []         \n5  [0073049557, 0134454170, 1118142063, 007733968...         \n6                                       [0330509691]         \n7  [B01NAJ3KQB, B00WYSPT0C, B00AF40U5G, B00OFVNM4...         \n8                                                 []         \n9                                                 []         \n\n                                          brand  \\\n0                                     GeoVision   \n1                                  33 Books Co.   \n2  Visit Amazon's Carolina Garcia Aguilera Page   \n3           Visit Amazon's Dick Gackenbach Page   \n4              Visit Amazon's Lolita Files Page   \n5         Visit Amazon's Alan Giambattista Page   \n6                                      ABBY LEE   \n7                                    Crazy Cart   \n8                               Enter The Arena   \n9                                Kelby Training   \n\n                                             feature  \\\n0  [Genuine Geovision 1 Channel NVR IP Software, ...   \n1  [Detailed chapters cover these fundamental top...   \n2                                                 []   \n3                                                 []   \n4                                                 []   \n5                                                 []   \n6                                                 []   \n7  [Package Content: 1 x Display MP3 Player 1 x E...   \n8  [Superb Sound Quality: Plays crystal clear aud...   \n9                                                 []   \n\n                                                rank  \\\n0  [>#3,092 in Tools &amp; Home Improvement &gt; ...   \n1  [>#55,933 in Camera &amp; Photo (See Top 100 i...   \n2                               3,105,177 in Books (   \n3                               2,024,298 in Books (   \n4                               3,778,828 in Books (   \n5                               3,330,771 in Books (   \n6                               3,304,037 in Books (   \n7  [>#177,454 in Electronics (See Top 100 in Elec...   \n8  [>#950 in Cell Phones & Accessories (See Top 1...   \n9  [>#932,732 in Computers &amp; Accessories &gt;...   \n\n                                           also_view              main_cat  \\\n0                                                 []    Camera &amp; Photo   \n1               [0943396670, 1138055360, 0999470906]    Camera &amp; Photo   \n2                                                 []                 Books   \n3               [0060219521, 0060219475, 0060219394]                 Books   \n4                                                 []                 Books   \n5  [0073512141, 0077339681, 0073049557, 007304956...                 Books   \n6                                       [B0719LDQR1]                 Books   \n7  [B01NAJ3KQB, B00OFVNM4G, B00L41WY8K, B07F34PNP...       All Electronics   \n8                                                 []  Home Audio & Theater   \n9                                                 []             Computers   \n\n                                        similar_item               date  \\\n0                                                      January 28, 2014   \n1                                                         June 17, 2003   \n2                                                                         \n3                                                                         \n4                                                                         \n5                                                                         \n6                                                                         \n7   class=\"a-bordered a-horizontal-stripes  a-spa...  December 28, 2012   \n8                                                      October 23, 2017   \n9                                                      December 9, 2011   \n\n                                               price        asin  \\\n0                                             $65.00  0011300000   \n1                                                     0043396828   \n2                                             $11.49  0060009810   \n3  .a-section.a-spacing-mini{margin-bottom:6px!im...  0060219602   \n4                                             $13.95  0060786817   \n5                                                     0070524076   \n6                                              $4.76  0091912407   \n7                                                     0101635370   \n8                                              $7.99  0132492776   \n9                                                     0132793040   \n\n                                            imageURL  \\\n0  [https://images-na.ssl-images-amazon.com/image...   \n1  [https://images-na.ssl-images-amazon.com/image...   \n2                                                 []   \n3                                                 []   \n4                                                 []   \n5                                                 []   \n6                                                 []   \n7  [https://images-na.ssl-images-amazon.com/image...   \n8  [https://images-na.ssl-images-amazon.com/image...   \n9  [https://images-na.ssl-images-amazon.com/image...   \n\n                                     imageURLHighRes details  \n0  [https://images-na.ssl-images-amazon.com/image...     NaN  \n1  [https://images-na.ssl-images-amazon.com/image...     NaN  \n2                                                 []     NaN  \n3                                                 []     NaN  \n4                                                 []     NaN  \n5                                                 []     NaN  \n6                                                 []     NaN  \n7  [https://images-na.ssl-images-amazon.com/image...     NaN  \n8  [https://images-na.ssl-images-amazon.com/image...     NaN  \n9  [https://images-na.ssl-images-amazon.com/image...     NaN  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Filter rows where the category contains 'Headphones'\nheadphones_df = df1[df1['category'].apply(lambda x: 'Headphones' in x)]\n\n# Print the number of rows\nprint(\"Number of rows related to headphones:\", len(headphones_df))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:48:20.180747Z","iopub.execute_input":"2024-04-07T07:48:20.181251Z","iopub.status.idle":"2024-04-07T07:48:21.056379Z","shell.execute_reply.started":"2024-04-07T07:48:20.181210Z","shell.execute_reply":"2024-04-07T07:48:21.055096Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Number of rows related to headphones: 31115\n","output_type":"stream"}]},{"cell_type":"code","source":"\nheadphones_df = df1[df1['category'].apply(lambda x: 'Headphones' in x)]\n\n# Displaying the selected headphones\n#print(headphones_df)\nprint(headphones_df.head(2))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T10:04:19.147369Z","iopub.execute_input":"2024-04-07T10:04:19.147820Z","iopub.status.idle":"2024-04-07T10:04:19.965576Z","shell.execute_reply.started":"2024-04-07T10:04:19.147786Z","shell.execute_reply":"2024-04-07T10:04:19.964408Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"                                        category tech1  \\\n8   [Electronics, Headphones, Earbud Headphones]         \n47                     [Electronics, Headphones]         \n\n                                          description fit  \\\n8   [, <b>True High Definition Sound:</b><br>With ...       \n47  [Use these high quality headphones for interne...       \n\n                                                title also_buy tech2  \\\n8   Wireless Bluetooth Headphones Earbuds with Mic...       []         \n47  Polaroid Pbm2200 PC / Gaming Stereo Headphones...       []         \n\n              brand                                            feature  \\\n8   Enter The Arena  [Superb Sound Quality: Plays crystal clear aud...   \n47         Polaroid  [Ideal for PC Internet chatting, PC / Console ...   \n\n                                                 rank also_view  \\\n8   [>#950 in Cell Phones & Accessories (See Top 1...        []   \n47  [>#3,548,269 in Cell Phones &amp; Accessories ...        []   \n\n                main_cat similar_item               date  price        asin  \\\n8   Home Audio & Theater                October 23, 2017  $7.99  0132492776   \n47       All Electronics               December 13, 2012         0558835155   \n\n                                             imageURL  \\\n8   [https://images-na.ssl-images-amazon.com/image...   \n47  [https://images-na.ssl-images-amazon.com/image...   \n\n                                      imageURLHighRes details  \n8   [https://images-na.ssl-images-amazon.com/image...     NaN  \n47  [https://images-na.ssl-images-amazon.com/image...     NaN  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Total number of rows in headphone","metadata":{}},{"cell_type":"code","source":"num_rows = headphones_df.shape[0]\nprint(\"Number of rows in the DataFrame:\", num_rows)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T08:50:23.821601Z","iopub.execute_input":"2024-04-07T08:50:23.822174Z","iopub.status.idle":"2024-04-07T08:50:23.830499Z","shell.execute_reply.started":"2024-04-07T08:50:23.822137Z","shell.execute_reply":"2024-04-07T08:50:23.829064Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Number of rows in the DataFrame: 31115\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check for columns with lists\nfor column in headphones_df.columns:\n    if isinstance(headphones_df[column].iloc[0], list):\n        print(f\"Column '{column}' contains lists.\")\n\n# Handle columns with lists (for example, convert them to strings)\n# Assuming 'category' is the column containing lists\nheadphones_df['category'] = headphones_df['category'].apply(lambda x: ', '.join(x))\n\n# Now you can proceed with preprocessing steps\n# Step 1: Count the total number of rows for the product\ntotal_rows = headphones_df.shape[0]\nprint(\"Total number of rows for the product 'Headphones':\", total_rows)\n\n# Step 2: Handle missing values\n# You can choose to drop rows with missing values or impute them depending on your specific requirements.\n# For example, to drop rows with missing values:\nheadphones_df.dropna(inplace=True)\n\n# Step 3: Handle duplicates\n# Drop duplicate rows if any\nheadphones_df.drop_duplicates(inplace=True)\n\n# After preprocessing, report the updated total number of rows\nupdated_rows = headphones_df.shape[0]\nprint(\"Total number of rows after preprocessing:\", updated_rows)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T09:31:08.309967Z","iopub.execute_input":"2024-04-07T09:31:08.310464Z","iopub.status.idle":"2024-04-07T09:31:08.826398Z","shell.execute_reply.started":"2024-04-07T09:31:08.310428Z","shell.execute_reply":"2024-04-07T09:31:08.822074Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Column 'category' contains lists.\nColumn 'description' contains lists.\nColumn 'also_buy' contains lists.\nColumn 'feature' contains lists.\nColumn 'also_view' contains lists.\nColumn 'imageURL' contains lists.\nColumn 'imageURLHighRes' contains lists.\nTotal number of rows for the product 'Headphones': 31076\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_32/2007384118.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  headphones_df['category'] = headphones_df['category'].apply(lambda x: ', '.join(x))\n/tmp/ipykernel_32/2007384118.py:18: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  headphones_df.dropna(inplace=True)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m headphones_df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Step 3: Handle duplicates\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Drop duplicate rows if any\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mheadphones_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_duplicates\u001b[49m\u001b[43m(\u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# After preprocessing, report the updated total number of rows\u001b[39;00m\n\u001b[1;32m     25\u001b[0m updated_rows \u001b[38;5;241m=\u001b[39m headphones_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:6805\u001b[0m, in \u001b[0;36mDataFrame.drop_duplicates\u001b[0;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6802\u001b[0m inplace \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(inplace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6803\u001b[0m ignore_index \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(ignore_index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 6805\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduplicated\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   6806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[1;32m   6807\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(result))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:6945\u001b[0m, in \u001b[0;36mDataFrame.duplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6944\u001b[0m     vals \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m subset)\n\u001b[0;32m-> 6945\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   6947\u001b[0m     ids \u001b[38;5;241m=\u001b[39m get_group_index(labels, \u001b[38;5;28mtuple\u001b[39m(shape), sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   6948\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(duplicated(ids, keep), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:6913\u001b[0m, in \u001b[0;36mDataFrame.duplicated.<locals>.f\u001b[0;34m(vals)\u001b[0m\n\u001b[1;32m   6912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(vals) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m-> 6913\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28mlen\u001b[39m(shape)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[1;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[0;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[1;32m    803\u001b[0m         uniques,\n\u001b[1;32m    804\u001b[0m         codes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    808\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[0;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[1;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[0;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[1;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7281\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7195\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"],"ename":"TypeError","evalue":"unhashable type: 'list'","output_type":"error"}]},{"cell_type":"code","source":"# Convert columns with lists to strings\nlist_columns = ['category', 'description', 'also_buy', 'feature', 'also_view', 'imageURL', 'imageURLHighRes']\nfor column in list_columns:\n    headphones_df[column] = headphones_df[column].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n\n# Now you can proceed with preprocessing steps\n# Step 1: Count the total number of rows for the product\ntotal_rows = headphones_df.shape[0]\nprint(\"Total number of rows for the product 'Headphones':\", total_rows)\n\n# Step 2: Handle missing values\n# You can choose to drop rows with missing values or impute them depending on your specific requirements.\n# For example, to drop rows with missing values:\nheadphones_df.dropna(inplace=True)\n\n# Step 3: Handle duplicates\n# Drop duplicate rows if any\nheadphones_df.drop_duplicates(inplace=True)\n\n# After preprocessing, report the updated total number of rows\nupdated_rows = headphones_df.shape[0]\nprint(\"Total number of rows after preprocessing:\", updated_rows)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T09:32:19.686861Z","iopub.execute_input":"2024-04-07T09:32:19.687331Z","iopub.status.idle":"2024-04-07T09:32:21.230439Z","shell.execute_reply.started":"2024-04-07T09:32:19.687300Z","shell.execute_reply":"2024-04-07T09:32:21.228521Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_32/140331190.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  headphones_df[column] = headphones_df[column].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n","output_type":"stream"},{"name":"stdout","text":"Total number of rows for the product 'Headphones': 31076\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_32/140331190.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  headphones_df.dropna(inplace=True)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m headphones_df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Step 3: Handle duplicates\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Drop duplicate rows if any\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mheadphones_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_duplicates\u001b[49m\u001b[43m(\u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# After preprocessing, report the updated total number of rows\u001b[39;00m\n\u001b[1;32m     21\u001b[0m updated_rows \u001b[38;5;241m=\u001b[39m headphones_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:6805\u001b[0m, in \u001b[0;36mDataFrame.drop_duplicates\u001b[0;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6802\u001b[0m inplace \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(inplace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6803\u001b[0m ignore_index \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(ignore_index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 6805\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduplicated\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   6806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[1;32m   6807\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(result))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:6945\u001b[0m, in \u001b[0;36mDataFrame.duplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6944\u001b[0m     vals \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m subset)\n\u001b[0;32m-> 6945\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   6947\u001b[0m     ids \u001b[38;5;241m=\u001b[39m get_group_index(labels, \u001b[38;5;28mtuple\u001b[39m(shape), sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   6948\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(duplicated(ids, keep), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:6913\u001b[0m, in \u001b[0;36mDataFrame.duplicated.<locals>.f\u001b[0;34m(vals)\u001b[0m\n\u001b[1;32m   6912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(vals) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m-> 6913\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28mlen\u001b[39m(shape)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[1;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[0;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[1;32m    803\u001b[0m         uniques,\n\u001b[1;32m    804\u001b[0m         codes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    808\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[0;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[1;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[0;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[1;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7281\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7195\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"],"ename":"TypeError","evalue":"unhashable type: 'list'","output_type":"error"}]},{"cell_type":"code","source":"ratings = []\n\nfor review in parse(\"/kaggle/input/ir-assignment3/Electronics_5.json\"):\n  ratings.append(review['overall'])\n\nprint(sum(ratings) / len(ratings))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T08:50:26.223443Z","iopub.execute_input":"2024-04-07T08:50:26.223928Z","iopub.status.idle":"2024-04-07T08:52:03.215100Z","shell.execute_reply.started":"2024-04-07T08:50:26.223885Z","shell.execute_reply":"2024-04-07T08:52:03.213844Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"4.26766835964799\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 4","metadata":{}},{"cell_type":"code","source":"# a. Number of Reviews\nnum_reviews = len(df)\n\n# b. Average Rating Score\naverage_rating = df['overall'].mean()\n\n# c. Number of Unique Products\nnum_unique_products = df['asin'].nunique()\n\n# d. Number of Good Ratings (>=3)\ngood_ratings = df[df['overall'] >= 3]['asin'].nunique()\n\n# e. Number of Bad Ratings (<3)\nbad_ratings = num_unique_products - good_ratings\n\n# f. Number of Reviews corresponding to each Rating\nrating_counts = df['overall'].value_counts().sort_index()\n\n# Print the results\nprint(\"a. Number of Reviews:\", num_reviews)\nprint(\"b. Average Rating Score:\", average_rating)\nprint(\"c. Number of Unique Products:\", num_unique_products)\nprint(\"d. Number of Good Ratings (>=3):\", good_ratings)\nprint(\"e. Number of Bad Ratings (<3):\", bad_ratings)\nprint(\"f. Number of Reviews corresponding to each Rating:\")\nprint(rating_counts)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T09:22:21.134848Z","iopub.execute_input":"2024-04-07T09:22:21.135341Z","iopub.status.idle":"2024-04-07T09:22:44.778469Z","shell.execute_reply.started":"2024-04-07T09:22:21.135309Z","shell.execute_reply":"2024-04-07T09:22:44.777136Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"a. Number of Reviews: 6739590\nb. Average Rating Score: 4.26766835964799\nc. Number of Unique Products: 160052\nd. Number of Good Ratings (>=3): 159978\ne. Number of Bad Ratings (<3): 74\nf. Number of Reviews corresponding to each Rating:\noverall\n1.0     467158\n2.0     306676\n3.0     504781\n4.0    1137393\n5.0    4323582\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport unicodedata\nimport string\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import wordnet\n\n# Function to remove HTML tags\ndef remove_html_tags(text):\n    clean_text = re.sub(r'<.*?>', '', text)\n    return clean_text\n\n# Function to remove accented characters\ndef remove_accented_chars(text):\n    clean_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n    return clean_text\n\n# Function to expand common acronyms\ndef expand_acronyms(text):\n    acronyms = {\n        \"n't\": \"not\",\n        \"'ve\": \"have\",\n        \"'ll\": \"will\",\n        \"'re\": \"are\",\n        \"'m\": \"am\",\n        \"'s\": \"is\",\n        \"'d\": \"would\",\n    }\n    words = text.split()\n    expanded_text = ' '.join([acronyms.get(word, word) for word in words])\n    return expanded_text\n\n# Function to remove special characters\ndef remove_special_characters(text):\n    clean_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    return clean_text\n\n# Function for lemmatization\ndef lemmatize_text(text):\n    lemmatizer = WordNetLemmatizer()\n    tokens = word_tokenize(text)\n    lemmatized_tokens = [lemmatizer.lemmatize(token, wordnet.VERB) for token in tokens]\n    lemmatized_text = ' '.join(lemmatized_tokens)\n    return lemmatized_text\n\n# Function for text normalization\ndef normalize_text(text):\n    text = text.lower()  # Convert text to lowercase\n    text = remove_html_tags(text)\n    text = remove_accented_chars(text)\n    text = expand_acronyms(text)\n    text = remove_special_characters(text)\n    text = lemmatize_text(text)\n    return text\n\n# Apply preprocessing functions to the 'reviewText' column\ndf['reviewText'] = df['reviewText'].apply(normalize_text)\n\n# Print the preprocessed text\nprint(df['reviewText'])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T09:28:48.220684Z","iopub.execute_input":"2024-04-07T09:28:48.221842Z","iopub.status.idle":"2024-04-07T09:28:49.599114Z","shell.execute_reply.started":"2024-04-07T09:28:48.221793Z","shell.execute_reply":"2024-04-07T09:28:49.597138Z"},"trusted":true},"execution_count":18,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:80\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m e\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/data.py:653\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    652\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (sep, msg, sep)\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/wordnet.zip/wordnet/.zip/' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Apply preprocessing functions to the 'reviewText' column\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreviewText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalize_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Print the preprocessed text\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4791\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n","File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","Cell \u001b[0;32mIn[18], line 53\u001b[0m, in \u001b[0;36mnormalize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     51\u001b[0m text \u001b[38;5;241m=\u001b[39m expand_acronyms(text)\n\u001b[1;32m     52\u001b[0m text \u001b[38;5;241m=\u001b[39m remove_special_characters(text)\n\u001b[0;32m---> 53\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mlemmatize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n","Cell \u001b[0;32mIn[18], line 42\u001b[0m, in \u001b[0;36mlemmatize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     40\u001b[0m lemmatizer \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n\u001b[1;32m     41\u001b[0m tokens \u001b[38;5;241m=\u001b[39m word_tokenize(text)\n\u001b[0;32m---> 42\u001b[0m lemmatized_tokens \u001b[38;5;241m=\u001b[39m [lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(token, wordnet\u001b[38;5;241m.\u001b[39mVERB) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens]\n\u001b[1;32m     43\u001b[0m lemmatized_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lemmatized_tokens)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lemmatized_text\n","Cell \u001b[0;32mIn[18], line 42\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m lemmatizer \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n\u001b[1;32m     41\u001b[0m tokens \u001b[38;5;241m=\u001b[39m word_tokenize(text)\n\u001b[0;32m---> 42\u001b[0m lemmatized_tokens \u001b[38;5;241m=\u001b[39m [lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(token, \u001b[43mwordnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVERB\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens]\n\u001b[1;32m     43\u001b[0m lemmatized_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lemmatized_tokens)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lemmatized_text\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:116\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir, zip_name))\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:78\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir, zip_name))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/data.py:653\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    651\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    652\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (sep, msg, sep)\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/wordnet' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************"],"ename":"LookupError","evalue":"\n**********************************************************************\n  Resource 'corpora/wordnet' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************","output_type":"error"}]}]}